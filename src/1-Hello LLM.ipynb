{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f200d0-9730-4c6b-8044-4bd799d24611",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 从零开始的LLM进修之路（一） 大模型的Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073c43d-90a8-41d0-911b-38f801dd2d22",
   "metadata": {
    "tags": []
   },
   "source": [
    "> 开篇：笔者在23年做了一些有关大模型的研究工作，在进行学习时深感中文资料的参差不齐。技术大牛们的Blog写的非常棒，不过在读者技术不到位时，读起来往往不得其中玄妙。说来说去，能读到大牛们上手门槛较高的高质量文章就已经够令人知足的，更多的是不知所以然的复制粘贴和营销号文章。所以，想要写一点有意思的入门教程，让后面学LLM的人少走一些弯路。当然这只是笔者决定开篇写作当前这个系列的一个原因，笔者又没把乐山大佛搬走自己上去坐，没有那么无私。还有两个重要原因，一个是笔者本身也算不上技术大牛，并且还是一个自认为比较愚钝的人，往往有些地方学的一知半解。而在重新梳理整理打算写给别人的过程中，总不能胡乱的去误导他人，这就要求自己去更深入的了解，直到完全吃透了，这对自己也是一种提升。另一个则是通过这个系列的抛砖引玉，想认识一些志同道合的朋友，一起学习进步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073b1be-125a-4e0a-b241-d735ddaf7309",
   "metadata": {},
   "source": [
    "## 1. 前言\n",
    "就像我们刚开始学习coding时，我们第一个打出来的一般都是`Hello，world!`一样，学习LLM相关技术时，笔者认为也有这样一个`Hello LLM!`。本篇文章中，就将介绍这样一个Hello LLM。由于本文的内容是用中文讲述的，所以在前几篇文章中，我们就先使用[ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)，这个中文能力很强的模型作为我们的第一个LLM。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47501ef-db7a-4050-a1f3-062bfd130103",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. 准备阶段\n",
    "\n",
    "### 2.1 环境配置\n",
    "考虑到GitHub连接不太稳定，这里附上requirements（运行所需的安装）。\n",
    "\n",
    "`pip install protobuf, transformers==4.30.2, cpm_kernels, torch>=2.0, gradio, mdtex2html, sentencepiece, accelerate, sse-starlette, streamlit>=1.24.0`\n",
    "\n",
    "> 考虑到本文读者可能并没有自己的算力,又或者安装cuda对于新人来说是一个相当麻烦的问题,推荐可以去[AutoDL](https://www.autodl.com/)租一台服务器用,他们已经帮你配置好了大部分的东西,非常方便。\n",
    "> 跟随入门文章学习时租一个3080就ok,一个小时1块钱不到。\n",
    "\n",
    "> ps:笔者现在就在AutoDL上编写当前的内容。\n",
    "\n",
    "### 2.2 模型下载\n",
    "我们既然要运行模型,那我们就需要这个模型。[hugging face](https://huggingface.co/)上提供了非常非常多的权重（其实就是预训练好的模型），我们需要的ChatGLM2在上面也有发布，笔者建议在hugging face上下载到你的工作目录之下。这样做的原因是简单且直观，还有一个就是通过hugging face的方法下载起来可能比较慢。我们就假设你的工作目录是`LLM_Study`,我们把模型文件和其他所需的文件存储在`LLM_Study/model/chatglm2`中。如果你的显存很少,那么我推荐你下载[int4版本](https://huggingface.co/THUDM/chatglm2-6b-int4)，只要3.92GB，显存足够的话也可以下载完整的[6b版本](https://huggingface.co/THUDM/chatglm2-6b)。\n",
    "\n",
    "ok，到这里我们已经做完了LLM hello world程序的所有准备工作了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32431c24-dfaf-467b-bae7-a4b2e7204bc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Hello LLM\n",
    "> 以下的内容推荐读者在jupyter中进行,使用IDE时,加载完模型,报错关掉重新加载实在是令人恼火哈!\n",
    "\n",
    "先给出一段官方的Quick Start，接下来我们就根据官方的Quick Start体验一下ChatGLM2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19320b9e-1ced-41a5-a1ca-cb564722d12e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00805974006652832,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b12b30def074fa1808946dfd0fb910f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../model/chatglm2\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"../model/chatglm2\", trust_remote_code=True).half().cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d48989-85cc-4a24-86c3-42bdbf98d1c6",
   "metadata": {},
   "source": [
    "上面的代码加载了`tokenizer`和`model`,是后面调用模型时必须要使用的两个关键变量。还有model.eval(),也是必须的一步,它将模型设置为评估模式。\n",
    "\n",
    "这里只需要知道上面这几步是必须的就可以了,在编写`Hello World`的时候,`#include<stdio.h>`, `main()`, `printf()`我们不也是一知半解吗~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b17dbef-f760-4dc8-8297-acf707d79df8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。\n",
      "如果你晚上睡不着，可以尝试以下一些方法来帮助你入睡：\n",
      "\n",
      "1. 放松你的身体：你可以试着放松你的身体，深呼吸或做一些轻松的伸展运动，以缓解身体的紧张。\n",
      "\n",
      "2. 放松你的大脑：你可以尝试进行冥想、放松音乐或白噪音等，以帮助你放松大脑。\n",
      "\n",
      "3. 创造一个舒适的睡眠环境：你可以保持卧室安静、凉爽、黑暗、舒适，以帮助自己放松和入睡。\n",
      "\n",
      "4. 避免使用电子设备：在睡觉前一小时内避免使用电子设备，如手机、电脑等，以避免刺激大脑。\n",
      "\n",
      "5. 规律作息：尽量在同一时间入睡和起床，帮助身体建立一个规律的睡眠时间表。\n",
      "\n",
      "6. 避免饮用刺激性饮料：例如咖啡、茶、可乐等，这些饮料中的咖啡因会让大脑更加兴奋，难以入睡。\n",
      "\n",
      "7. 远离刺激性活动：在睡觉前几小时内避免进行刺激性活动，例如激烈的运动或紧张的活动。\n",
      "\n",
      "如果你尝试了以上方法仍然睡不着，可以尝试联系医生或专业的心理健康医师，以获取更好的帮助。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "print(response)\n",
    "response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c5b5e-bb6e-4124-8f91-c7dde18b927b",
   "metadata": {},
   "source": [
    "我们已经成功的和一个语言模型进行了交谈，Hello,LLM!👍\n",
    "\n",
    "可能你现在已经复制了上面的代码\n",
    "\n",
    "`\n",
    "response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n",
    "print(response)\n",
    "`\n",
    "\n",
    "然而你惊奇的发现,为什么这个语言模型现在好像总往晚上睡不着去聊，明明我问他的问题跟之前的没什么关系。可在Hello LLM之后,还想跟它聊点别的该怎么办，难道要重启程序吗？\n",
    "\n",
    "其实问题藏在`history`当中,`history`中存储了我们的上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3748fc09-1347-4e2a-961d-ac6322829d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('你好', '你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。'), ('晚上睡不着应该怎么办', '如果你晚上睡不着，可以尝试以下一些方法来帮助你入睡：\\n\\n1. 放松你的身体：你可以试着放松你的身体，深呼吸或做一些轻松的伸展运动，以缓解身体的紧张。\\n\\n2. 放松你的大脑：你可以尝试进行冥想、放松音乐或白噪音等，以帮助你放松大脑。\\n\\n3. 创造一个舒适的睡眠环境：你可以保持卧室安静、凉爽、黑暗、舒适，以帮助自己放松和入睡。\\n\\n4. 避免使用电子设备：在睡觉前一小时内避免使用电子设备，如手机、电脑等，以避免刺激大脑。\\n\\n5. 规律作息：尽量在同一时间入睡和起床，帮助身体建立一个规律的睡眠时间表。\\n\\n6. 避免饮用刺激性饮料：例如咖啡、茶、可乐等，这些饮料中的咖啡因会让大脑更加兴奋，难以入睡。\\n\\n7. 远离刺激性活动：在睡觉前几小时内避免进行刺激性活动，例如激烈的运动或紧张的活动。\\n\\n如果你尝试了以上方法仍然睡不着，可以尝试联系医生或专业的心理健康医师，以获取更好的帮助。')]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67643112-ba8e-4b8f-818f-1b2cbcd829a5",
   "metadata": {},
   "source": [
    "我们把`history`清空掉,这个时候语言模型就会跟我们聊新的话题了!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cec11a6-c03d-4858-ac94-f19a1fa7a217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学习大型语言模型需要一定的计算机科学知识和编程经验。以下是一些入门指南:\n",
      "1. 学习编程语言:大型语言模型通常使用Python编程语言实现,因此学习Python编程语言是必不可少的。建议先学习Python的基础语法,然后学习Python的高级特性和大型语言模型的实现方法。\n",
      "2. 学习深度学习:大型语言模型通常使用深度学习技术实现,因此需要学习深度学习的基本原理和常见的深度学习框架,如TensorFlow和PyTorch。\n",
      "3. 学习自然语言处理:大型语言模型通常需要进行自然语言处理(NLP)的训练和调整,因此需要学习NLP的基本原理和技术,如分词、词性标注、命名实体识别、语义分析等。\n",
      "4. 学习大型语言模型的实现方法:大型语言模型的实现方法因模型而异,需要学习相应的实现方法。常见的实现方法包括 transformer、循环神经网络(RNN)、支持向量机(SVM)等。\n",
      "5. 实践项目:通过实践项目来深入学习大型语言模型的实现方法和应用。可以参加一些开源项目或者自己实现一个大型语言模型项目,如 Chatbot、机器翻译等。\n",
      "\n",
      "学习大型语言模型需要一定的计算机科学知识和编程经验,需要有耐心和实践。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"大型语言模型该怎么入门\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4195bd-d2ff-46c6-8dd3-6d1f696d1a5b",
   "metadata": {},
   "source": [
    "🎉🎉🎉**到这里为止,我们就已经在代码层面上调用了一个大型语言模型!**🎉🎉🎉\n",
    "---\n",
    "> 如果觉得内容有帮助，可以关注dian，本系列将持续更新。\n",
    "[项目地址](https://github.com/ydyjya/llm_note)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
